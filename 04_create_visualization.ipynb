{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_create-visualization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPenkKPHSjAUlMrYiNxWSXG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FFI-Vietnam/camtrap-tools/blob/main/04_create_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjWfresJGQYe"
      },
      "source": [
        "\"\"\"\n",
        "This script evaluates recall accuracy of MegaDetector from a ground-truth dataset\n",
        "and a result json file. Then it creates a set of visualization of recall values \n",
        "on each group of species.\n",
        "\n",
        "After runnning this script, a 'visualizations' folder is created\n",
        "\n",
        "visualizations\n",
        "    |__ \n",
        "    \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKcm_qPwH2Ur"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import os\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U37AN-_IJU-7",
        "outputId": "d6d07ea6-247e-4d68-9aea-0a9f1352a1cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLYuK3JeJWqy"
      },
      "source": [
        "# specifies Colab directories and file names\n",
        "root = '/content/drive/'\n",
        "\n",
        "dataset_folder = 'My Drive/FFI/MegaDetector Test/confusion-matrix/dataset'\n",
        "contain_folder = 'My Drive/FFI/MegaDetector Test/confusion-matrix/data cleaning'\n",
        "image_folder = 'My Drive/FFI/MegaDetector Test/confusion-matrix/visualization'\n",
        "\n",
        "ground_truth_file_name = '01_ground-truth-table_Kon-Plong.csv'\n",
        "MD_result_file_name = 'MegaDetector_result_2021-08-27.json'\n",
        "taxon_match_table_file_name = '02_taxon-database-with-conservation-status.csv'\n",
        "confusion_matrix_file_name = '03_confusion-matrix.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7tQlpBCJpdA"
      },
      "source": [
        "# read and save file functions\n",
        "def read_csv_Google_drive(root, contain_folder, file_name):\n",
        "  file_path = os.path.join(root, contain_folder, file_name)\n",
        "  return pd.read_csv(file_path)\n",
        "\n",
        "def save_csv_Google_drive(df, root, contain_folder, file_name, index=False):\n",
        "  \"\"\"\n",
        "  function to save a csv file to Google Drive\n",
        "  param examples:\n",
        "    root = '/content/drive/'\n",
        "    contain_folder = 'My Drive/FFI/dataset'\n",
        "    file_name = 'image_metadata(2020-06-26)_full.csv'\n",
        "  \"\"\"\n",
        "  # save file to Colab runtime storage (will be deleted when this notebook is closed)\n",
        "  df.to_csv('dataframe.csv', index=index)\n",
        "\n",
        "  # save file back to Google Drive for permanent storage\n",
        "  folder_path = os.path.join(root, contain_folder)\n",
        "  file_path = os.path.join(root, contain_folder, file_name)\n",
        "  try:\n",
        "    os.makedirs(folder_path)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  with open('dataframe.csv', 'r') as f:\n",
        "    df_file = f.read()\n",
        "\n",
        "  with open(file_path, 'w') as f:\n",
        "    f.write(df_file)\n",
        "\n",
        "  print(f'File is saved to {file_name} in Google Drive at {file_path}')\n",
        "\n",
        "def save_image_Google_drive(plt, root, contain_folder, file_name):\n",
        "  \"\"\"\n",
        "  function to save an image file to Google Drive\n",
        "  param examples:\n",
        "    root = '/content/drive/'\n",
        "    contain_folder = 'My Drive/FFI/dataset'\n",
        "    file_name = 'MD_recall_all-species.jpg'\n",
        "  \"\"\"\n",
        "\n",
        "  # save file back to Google Drive for permanent storage\n",
        "  folder_path = os.path.join(root, contain_folder)\n",
        "  file_path = os.path.join(root, contain_folder, file_name)\n",
        "  try:\n",
        "    os.makedirs(folder_path)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  plt.savefig(file_path)\n",
        "  \n",
        "  print(f'File is saved to {file_name} in Google Drive at {file_path}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCNM8U5HLCug"
      },
      "source": [
        "def create_confusion_matrix_by_group(taxon_match_table, confusion_matrix, species_group):\n",
        "  \"\"\"\n",
        "  create a confusion matrix by species group, e.g. \"ungulates\", \"small carnivores\", \"birds\", \"small mammals (squirrels and rats)\", \"primates\"\n",
        "  @params species_group: dict {group_common_name: [taxonomical_level, group_scientific_name, except]}\n",
        "    example: {\"Birds\":[\"class\", \"Aves\", []], -> all Birds\n",
        "              \"Small carnivores\":[\"order\", \"Carnivora\", [\"Asian Black Bear\"]]} -> all carnivores excepts for Bears\n",
        "  \"\"\"\n",
        "  confusion_matrix_by_group = pd.DataFrame(index = ['Animal', 'Human', 'Blank', 'Total', 'Recall'])\n",
        "  for group in species_group.keys():\n",
        "    species_list = find_FFI_species_by_taxonomy(taxon_match_table, \n",
        "                                                species_group[group][0], \n",
        "                                                species_group[group][1])\n",
        "    # remove except species, e.g. Asian Black Bear not in Small Carnivores\n",
        "    species_list = list(set(species_list) - set(species_group[group][2]))\n",
        "    # remove unnecessary species such as Bat, Maxomys, etc\n",
        "    species_list = list(set(species_list) & set(confusion_matrix.columns))\n",
        "    # lump into one group\n",
        "    confusion_matrix_by_group[group] = confusion_matrix[species_list].astype('float').sum(axis = 1)\n",
        "\n",
        "  # update recall\n",
        "  for col in confusion_matrix_by_group.columns:\n",
        "    if col == 'Human':\n",
        "      confusion_matrix_by_group[col][4] = round(int(confusion_matrix_by_group[col][1]) / int(confusion_matrix_by_group[col][3]), 2)\n",
        "    else:\n",
        "      confusion_matrix_by_group[col][4] = round(int(confusion_matrix_by_group[col][0]) / int(confusion_matrix_by_group[col][3]), 2)\n",
        "  return confusion_matrix_by_group\n",
        "\n",
        "confusion_matrix_by_group = \\\n",
        "create_confusion_matrix_by_group(taxon_match_table, confusion_matrix, {'Ungulates'       :['order', 'Cetartiodactyla', []],\n",
        "                                                                       'Birds'           :['class', 'Aves', []],\n",
        "                                                                       'Small carnivores':['order', 'Carnivora', [\"Asian Black Bear\"]],\n",
        "                                                                       'Small mammals'   :['order', 'Rodentia', []],\n",
        "                                                                       'Primates'        :['order', 'Primates', ['Human']],\n",
        "                                                                       'Bear'            :['family', 'Ursidae', []],\n",
        "                                                                       'Pangolin'        :['family', 'Manidae', []],\n",
        "                                                                       'Human'           :['species', 'sapiens', []]\n",
        "                                                                       }) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLRC1jedLDlS"
      },
      "source": [
        "def create_confusion_matrix_by_conservation_status(taxon_match_table, confusion_matrix, conservation_status):\n",
        "  \"\"\"\n",
        "  create a confusion matrix by conservation status\n",
        "  @params conservation_status: list of status\n",
        "    example: [\"Endangered\", \"Vulnerable\"]\n",
        "  \"\"\"\n",
        "  def status_of(species):\n",
        "    return taxon_match_table[taxon_match_table['FFI_species_name'] == species]['conservation_status'].iat[0]\n",
        "  \n",
        "  confusion_matrix_by_conservation_status = pd.DataFrame(index = ['Animal', 'Human', 'Blank', 'Total', 'Recall'])\n",
        "  for species in confusion_matrix.columns:\n",
        "    try: # avoid unrecorded species such as Banded Krait\n",
        "      if status_of(species) in conservation_status:\n",
        "        confusion_matrix_by_conservation_status[species] = confusion_matrix[species]\n",
        "    except:\n",
        "      pass\n",
        "  return confusion_matrix_by_conservation_status\n",
        "\n",
        "confusion_matrix_by_conservation_status = \\\n",
        "create_confusion_matrix_by_conservation_status(taxon_match_table, confusion_matrix, [\"Endangered\", \"Vulnerable\", \"Critically Endangered\"])\n",
        "\n",
        "confusion_matrix_by_conservation_status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF_CR0A3LF6j"
      },
      "source": [
        "def create_confusion_matrix_in_group(taxon_match_table, confusion_matrix, species_group):\n",
        "  \"\"\"\n",
        "  create a confusion matrix in each species group, e.g. \"ungulates\", \"small carnivores\", \"birds\", \"small mammals (squirrels and rats)\", \"primates\"\n",
        "  @params species_group: list [group_common_name, taxonomical_level, group_scientific_name, except]\n",
        "    example: + [\"Birds\", \"class\", \"Aves\", []] -> for all Birds\n",
        "             + [\"Small carnivores\", \"order\", \"Carnivora\", [\"Asian Black Bear\"]]} -> for all carnivores excepts for Bears\n",
        "  \"\"\"\n",
        "  confusion_matrix_in_group = pd.DataFrame(index = ['Animal', 'Human', 'Blank', 'Total', 'Recall'])\n",
        "  species_list = find_FFI_species_by_taxonomy(taxon_match_table, \n",
        "                                              species_group[1], \n",
        "                                              species_group[2])\n",
        "  # remove except species, e.g. Asian Black Bear not in Small Carnivores\n",
        "  species_list = list(set(species_list) - set(species_group[3]))\n",
        "  # remove unnecessary species such as Bat, Maxomys, etc\n",
        "  species_list = list(set(species_list) & set(confusion_matrix.columns))\n",
        "  # get columns by species\n",
        "  confusion_matrix_in_group = confusion_matrix[species_list].astype('float')\n",
        "\n",
        "  # update recall\n",
        "  for col in confusion_matrix_in_group.columns:\n",
        "    if col == 'Human':\n",
        "      confusion_matrix_in_group[col][4] = round(int(confusion_matrix_in_group[col][1]) / int(confusion_matrix_in_group[col][3]), 2)\n",
        "    else:\n",
        "      confusion_matrix_in_group[col][4] = round(int(confusion_matrix_in_group[col][0]) / int(confusion_matrix_in_group[col][3]), 2)\n",
        "  return confusion_matrix_in_group\n",
        "\n",
        "confusion_matrix_in_group = create_confusion_matrix_in_group(taxon_match_table, confusion_matrix, ['Ungulates', 'order', 'Cetartiodactyla', []])\n",
        "confusion_matrix_in_group"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU1vYiNYLId9"
      },
      "source": [
        "def visualize_recall_bargraph(group_name, confusion_matrix, threshold, color_dict, num_image_threshold=0, legend_by_color=False, custom_size=None, save_fig=False):\n",
        "  \"\"\"\n",
        "  visualize recall values by bargraph by taxonomical class\n",
        "  \"\"\"\n",
        "\n",
        "  print(f\"Generating visualization plot for {group_name}...\")\n",
        "  total = []\n",
        "  recall = []\n",
        "  names = []\n",
        "  colors = []\n",
        "\n",
        "  image_count = len(mega_result['images'])\n",
        "\n",
        "  species_list = confusion_matrix.columns.to_list()\n",
        "  for species in species_list:\n",
        "    if species not in ['All']:\n",
        "      if confusion_matrix[species]['Total'] >= num_image_threshold:\n",
        "        colors.append(color_dict[species])\n",
        "        recall.append(confusion_matrix[species]['Recall'])\n",
        "        total.append(confusion_matrix[species]['Total'])\n",
        "        names.append((species))\n",
        "\n",
        "  # create df to sort recall values\n",
        "  recall_stats = pd.DataFrame({'name':names, 'recall':recall, 'total':total, 'colors':colors})\n",
        "  recall_stats['recall'] = recall_stats['recall'].astype('float')\n",
        "  recall_stats['total'] = recall_stats['total'].astype('int')\n",
        "  recall_stats.sort_values('recall', inplace=True, ascending=True)\n",
        "\n",
        "  # creating the bar plot\n",
        "  species_name = recall_stats['name'].to_list()\n",
        "  values = recall_stats['recall'].to_list()\n",
        "  total = recall_stats['total'].to_list()\n",
        "  colors = recall_stats['colors'].to_list()\n",
        "  avg_recall = np.mean(recall_stats['recall'])\n",
        "\n",
        "  if custom_size:\n",
        "    fig = plt.figure(figsize=custom_size)\n",
        "    \n",
        "  plt.barh(species_name, values, color=colors)\n",
        "  for i, v in enumerate(values):\n",
        "    recall_value_text_location = v\n",
        "    plt.text(recall_value_text_location, i, str(round(v,2)), color='blue', fontweight='bold')\n",
        "    if not custom_size:\n",
        "      num_image_text_location = v + 0.09\n",
        "    else:\n",
        "      num_image_text_location = v + 1/(1.5*custom_size[0])\n",
        "    plt.text(num_image_text_location, i, f'{str(total[i])} images', color='blue', fontweight='bold')\n",
        "  # for i, v in enumerate(total):\n",
        "\n",
        "  plt.xlabel(\"Values\")\n",
        "  plt.ylabel(\"Species name\")\n",
        "  labels = list(color_map.keys())\n",
        "  if legend_by_color:\n",
        "    handles = [plt.Rectangle((0,0),1,1, color=color_map[label]) for label in labels]\n",
        "    plt.legend(handles, labels)\n",
        "  plt.title(f\"Evaluate over {image_count} images for {group_name}\" +\n",
        "            f\"\\nminimum image amount: {num_image_threshold}\" +\n",
        "            f\"\\nthreshold:  {threshold}\" +\n",
        "            f\"\\naverage_recall_value: {round(avg_recall,2)}\")\n",
        "  if save_fig:\n",
        "    save_image_Google_drive(plt, root, image_folder, save_fig)\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDJuL1siLfeY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}